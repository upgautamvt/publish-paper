\section{Motivational Analysis}

The BPF verifier places strong constraints on programs.
These are important for verifying safe code, but they present a serious usability problem.
Developers have a contract with the programming language that is enforced by the compiler of interpreter.
The programmer also has a contract with the BPF verifier, but it is hard to know if the contract has been followed.
Source code goes through a translation to BPF bytecode before it is verified, which makes mapping the output of the verifier back to the code the programmer wrote difficult.
Additionally, the cause of verifier rejections may be unrelated to the code the programmer wrote.

To explore the range of verifier issues that BPF developers face, we carried out an analysis of existing BPF projects and research papers.
BPF developers often have to wrestle with the in-kernel verifier to allow the programs they write to pass.
This can manifest itself in needing to write arcane expressions to please the verifier.
We categorize the solutions that programmers need to implement in order to pass the verifier.

\subsection{Methodology}
To capture data, we searched through the git commit logs of cilium, aya-rs, and katran, for instances of the keywords: "error", "reject", "rejects", "issue", and "verifer." 
For each commit log that matched, we manually inspected it to try and classify it.
Overall we captured XXX commit logs, of which we decided that YY of them were not actually realted to verifier complaints.
That left a total of ZZ commits that were related to the verifier.
The vast majority of commits that we found were from the cilium repository.

For each commit, we read the commit message, and examined the source code changes.
Some categories were clear to see and are well documented in the literature (i.e. splitting functions), while other categories were more subtle.
We created a qualitative analysis of many of the kinds of problems that arise when writing and verifiyng BPF programs.

\subsection{Results}

\begin{figure}
    \centering
    \begin{tabular}{|p{5cm}|p{2cm}|}
        \hline
        Category & \# Examples \\
        \hline
        General hacks to pass verifier & 34 \\
        \hline
        Modifying code to make LLVM generate the right bytecode & 21 \\
        \hline
        Splitting functions for the verifier & 12 \\
        \hline
        Add "pruning checkpoints" to reduce complexity & 7 \\
        \hline
        Needing to inline functions to pass verifier & 6 \\
        \hline
        Explicitly teaching the verifier information & 4 \\
        \hline
        Writing a special implemention of a helping function & 2 or 3 \\
        \hline
    \end{tabular}
    \caption{Table of common verifier problems}
    \label{fig:commit-table}
\end{figure}

In fig. ~\ref{fig:commit-table} we summarize the results of our analysis.
Each category represents a class of techniques that developers used to make their programs pass the verifier.

The composition of the categories makes it clear that developers have to change their code in particular ways to get it to pass the verifier.
It also proves out how difficult it can be to reason about the results of the verifier.

A BPF program can fail to verify for several reasons.
The first case is where the program is unsafe, and the verifier correctly rejects it.
The important other case is when the verifier gets it wrong.
When the verifier rejects a valid program, it is up to the developer to find a way to show the verifier that the program actually is safe.
The classes of solution employed are different ways that developers use to make sure the verifier accepts their programs.

\subsection{Examples}
To better explain our categorization, we will now walk through some characteristic examples for the most important categories.

\subsubsection{Fixing LLVM}
One issue found by cilium was that LLVM may generate 32-bit assignments for accesing \emph{ctx->data, ctx->data\_end, ctx->data\_meta} fields.
The verifier cannot track the packet pointers through these 32-bit assignments.
The solution was to implement the read through inline assembly code shown in figure ~\ref{fig:inline-asm}.
This causes LLVM to not know that it could generate 32-bit assignments as an optimization.



This workaround allows the BPF program to pass the verifier.
It is clear to see that this is not usable code.
The LLVM compiler is unaware of the verifiers needs, and the programmer must know low level detail about the BPF system in order to realize this.

Another change that was implemented was to mark certain variables as volatile.
This change keeps LLVM from performing other kinds of optimizations that would cause the program to be rejected by the verifier.

\begin{figure}
    \begin{lstlisting}[language=myC]
#define DEFINE_FUNC_CTX_POINTER(FIELD)
static __always_inline void *
ctx_ ## FIELD(const struct __sk_buff *ctx)
{
	void *ptr;
	asm volatile("%0 = *(u32 *)(%1 + %2)"
		     : "=r"(ptr)
		     : "r"(ctx), "i"(offsetof(struct __sk_buff, FIELD)));
	return ptr;	
}
    \end{lstlisting}
    \caption{Inline asm to access fields}
    \label{fig:inline-asm}
\end{figure}

\subsubsection{Adding Pruning Checkpoints}
Another common fix that cilium implemented was to introduce a pseudo-helper function \emph{relax\_verifier}.
The purpose of this helper is to provide a checkpoint for the verifier to use when does state pruning.
In some cases doing so significantly decreases the complexity of BPF programs.
In one commit, doing so reduced the number of instructions checked from 62,569 to 49,669.
This is more significant on older kernel versions which have a much smaller upper limit to the number of instructions the BPF verifier could check.

Again, this change is horrible from a usability standpoint.
With no assistance from their compiler, programmers must know design and then include code that enables the verifier's state pruning mechanism to kick in.

\subsubsection{Splitting Helper Functions}
A well documented technique to decrease overall BPF program complexity is to use BPF tail calls to split programs into several smaller subprograms that can be verified indepenently.
Research works like Electrode and BMC note that they had to use this technique in order to pass the verifier.
The idea behind the split is that if each individual piece is verified to be safe, then the verifier itself would have verified the entire program if it could check enough instructions.

From a software design perspective modularity is good, but when programmers are forced to split functions according to the verifiers needs it becomes less usable.
This compounds with the fact that the compiler has no notion of these limits.
The compiler would happily compile the split versions of code, and the unified version of code.
Only one set of code would compile.
Additionally, it is not necessarily trivial to split these functions because all safety checks need to be made in each subfunction.
