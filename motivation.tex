\section{Motivational Analysis}
\label{sec:motivation}

While eBPF verification is important for program safety, the eBPF verifier has
    to place additional constraints on programs, which results in usability
    challenges.
At the core of the problem is a large gap between the programmer and the
    verifier.
Typical eBPF development involves implementing programs in a high-level
    programming langauge (e.g., C, Rust) and compiling to eBPF bytecode.
Developers agree to a contract with the high-level language, which is enforced by the compiler.
When a program fails to compile, the developer will get a message with hints about where they violated
    the contract with the programming language.
At the same time, there is an implicit agreement between the developer and the eBPF verifier, which is
    checked by the verifier.
The verifier will reject programs that do not maintain the agreement.
Verifier rejections may be from truly unsafe programs, or from false positives.
Additionally, the cause of verifier rejections may even be unrelated to the code the programmer wrote.
As a result, eBPF developers often have to wrestle with the in-kernel verifier
    to allow the programs they write to pass.
This can manifest itself in needing to write arcane expressions to please the
    verifier.

%This binds developers with a contract not only with the high-level language
%    that is enforced by the compiler or interpreter, but also with the eBPF
%    verifier, where the specifications are not clear. \mvle{I don't it's an issue with specification. it's partly due to going from a turing-complete language to turing-incomplete. I think we should bulletize these challenges. 1. semantic gap (turing complete -> turing-incomplete, 2. difficult to debug due to many levels of translation, 3. compiler optimizations that are incompatible with verifier, 4. specification for verifier changes across kernel versions, 5. ?}
%Developers have a contract with the programming language that is enforced by the compiler of interpreter.
%The programmer also has a contract with the eBPF verifier, but the specifics are unclear.
%At the same time, because source code goes through a translation to eBPF
%    bytecode before verification, it is often difficult to map the verifier
%    error back to source code.
%Source code goes through a translation to eBPF bytecode before it is verified, which makes mapping the output of the verifier back to the code the programmer wrote difficult.

To better understand this gap and the kinds of usability issues the eBPF
    developers face, we carried out an analysis on existing eBPF projects and
    past research literatures.
%We carried out an analysis of existing eBPF projects and research papers to better understand this gap and the kinds of verifier issues the eBPF developers face.
% eBPF developers often have to wrestle with the in-kernel verifier to allow the programs they write to pass.
% This can manifest itself in needing to write arcane expressions to please the verifier.
We categorize the solutions that programmers need to implement in order to pass the verifier to get a clearer picture of the usability challenges that the current eBPF system has.

\jinghao{@Milo I restructured the preamable, please take a look to see if there
are any problems}

\subsection{Methodology}
To collect data, we searched through the git commit logs of Cilium, Aya-rs, and
    Katran, which are mature, widely-used eBPF projects, for instances of
    keywords: "error", "reject", "rejects", "issue", and "verifier."
For each commit log that matched, we manually inspected and classified the commit.% it to try and classify it.
In total, we collected 216 commit messages \mvle{containing the above keywords}, of which we decided that 73 of them were actually about verifier complaints.
In addition, we included \mvle{how many?} issues raised in the BMC~\cite{BMC} and Electrode~\cite{Electrode} papers as examples when appropriate.
\jinghao{Citation needed for all mentioned projects/papers.}

88\% of commit messages found were from the Cilium repository.
Cilium is a mature project that makes extensive use of eBPF as a core part of its architecture.
Cilium represents a representative set of challenges for large projects with complex eBPF code bases.
\jinghao{Is this paragraph necessary?}

To classify the commit into categories, we read the commit message and examined
    the source code changes.
Some categories were clear to see and are well documented in the literature (i.e. splitting functions), while other categories were more subtle.
We created a qualitative analysis of many of the kinds of problems that arise when writing and verifying eBPF programs.

\subsection{Results}

\begin{table}[t]
    \small
    \centering
    \begin{tabular}{lc}%{|p{6cm}|p{1cm}|}
        \toprule
        \textbf{Category} & \textbf{Count} \\
        \midrule
        Change source code to fix LLVM codegen & 22 \\          % #1
        Restructure eBPF program for verifier & 20 \\           % #2
        Add specific code to pass verifier & 17 \\              % #3
        Implement kernel-version-specific fixes & 9 \\          % #4
        Add "pruning checkpoints" to reduce complexity & 7 \\   % #5
        % moved to #2 Refactor code because of lack of expressiveness & 2 \\
        % moved to #2 Split eBPF programs for complexity & 13 \\
        % moved to #2 Refactor code to reduce complexity & 5 \\
        % moved to #3 Inline functions to pass verifier & 6 \\
        % moved to #3 Explicitly teach the verifier information & 6 \\
        % moved to #3 Add bounds to a helping function & 3 \\
        % moved to #3 Add a specific implementation of a helping function & 2 \\
        \bottomrule
    \end{tabular}
    \caption{Table of common verifier problems}
    \label{fig:commit-table}
\end{table}

Table~\ref{fig:commit-table} summarizes the results of our analysis.
Our analysis classifies the commits into 10 categories.
Each category represents a class of techniques that developers used to make their programs pass the verifier.

\jinghao{
Some comments on the table: it is not immediately clear on what exactly
    the developers are doing for some of the categories, especially the last
    3. (btw, should it be ``helper functions'' or ``helping functions'').
At the same time, the categories do not seem to be mutually exclusive,
    e.g., ``Split eBPF programs for complexity'' vs.
    ``Refactor code to reduce complexity''.
We should be clear whether the categories are overlapping.
}

The composition of the categories makes it clear that developers have to change their code in particular ways to get it to pass the verifier.
It also demonstrates how difficult it can be to reason about the results of the verifier.

An eBPF program can fail to verify for several reasons.
The first case is where the program is unsafe, and the verifier correctly rejects it.
The important other case is when the verifier gets it wrong.
When the verifier rejects a valid program, it is up to the developer to find a way to show the verifier that the program actually is safe.
The classes of solution employed are different ways that developers use to make sure the verifier accepts their programs.
\jinghao{This paragraph is reptitative given the preamable, I think what is
    missing here is an overview of the finding from our study (i.e. beef up the
    previous paragraph)}

\subsection{Examples}
To better explain our categorization, we will now walk through some characteristic examples for the most important categories.

\subsubsection{Change Source Code to Fix LLVM Codegen}
One issue found by Cilium was that LLVM may generate 32-bit assignments for accessing \emph{ctx->data, ctx->data\_end, ctx->data\_meta} fields.
The verifier cannot track the packet pointers through these 32-bit assignments.
The solution was to implement the access through inline assembly code shown in Figure~\ref{fig:inline-asm}.
This prevents LLVM from generating 32-bit assignments as an optimization.
\jinghao{can we be more specific on the BPF opcode (e.g., load/store) of the
    assignment as in Figure~\ref{fig:inline-asm}}



This workaround allows the eBPF program to pass the verifier.
It is clear that this exposes usability issues of the verifier.
%It is clear to see that this is not usable code.
The LLVM compiler is unaware of the verifier's needs, and the programmer must know low level detail about the eBPF system in order to realize this.

Another change that was implemented was to mark certain variables as volatile.
This change keeps LLVM from performing other kinds of optimizations that would cause the program to be rejected by the verifier.

\begin{figure}
    \lstinputlisting[language=myC]{./snippets/s2-inline-asm.c}
    \caption{Inline asm to access fields}
    \label{fig:inline-asm}
\end{figure}

\subsubsection{Restructure eBPF program for verifier}
A big theme across the commits we found was the need to explicitly restructure eBPF programs to pass the verifier.
We identified two main techniques for restructuring programs:

\begin{enumerate}
    \item Split eBPF programs into smaller subprograms
    \item General refactoring to reduce verifier complexity or bypass expressiveness limits
\end{enumerate}

\textbf{Splitting eBPF Programs}:
A well documented technique to decrease overall eBPF program complexity is to use eBPF tail calls to split programs into several smaller subprograms that can be verified independently.
The idea behind the split is that if each individual piece is verified to be safe, then the verifier itself would have verified the entire program if it could check enough instructions.
Prior works like BMC\cite{BMC} and Electrode\cite{Electrode} utilize this technique in order to pass the verifier.
BMC is split into seven different eBPF programs, and Electrode is split into 6 different eBPF programs.
Both of these projects use around 500 lines of C code to program the eBPF programs.

From a software design perspective modularity is good, but when programmers are forced to split functions according to verifier limitations, it becomes less usable.
This compounds with the fact that the compiler has no notion of these limits.
The compiler would happily compile both the split versions of code and the unified version of code, however only one set of code would pass the verifier.
Additionally, it is not necessarily trivial to split these functions because all safety checks need to be made in each subfunction in order for them to be independently verified.

\textbf{Refactoring Code}:
Code may also need to be refactored to reduce the verifier complexity, or to workaround limitations in the verifier.
One example of refactoring for complexity involved changing how the code handled IPv4 fragmentation.
The current state of the code caused the program to fail verification as it went over the maximum checked instruction limit. 
The code was refactored to reduce the number of calls to \verb{ctx_load_bytes(){, which solved the complexity issue.

One example of refactoring for expressiveness invovles implementing a switch statement inside of a switch statement which essentially duplicates code.
The main reason this was a problem is because the verifier would see the back edge jump to the beginning of the original switch statement.
The verifier would treat this as a potential infinite loop and reject the program.
\milo{Work on this and add better explanations/a figure maybe}

\subsubsection{Add specific code to pass verifier}
\textbf{Inlining Functions to Pass Verifier}:

The verifier can lose track of information depending on how eBPF programs are structured.
One fix for this is to inlined functions for implementing functionality.
It is not clear what code needs to be made into a inlined function for the verifier.
%Doing this helps to keep functionality separate from the programmers perspective, while allowing the verifier to see all the code at the same time.

\begin{figure}
    \begin{lstlisting}[language=myC]
policy_check_entry:
	account(ctx, policy);

	if (unlikely(policy->deny))
		return DROP_POLICY_DENY;

	*proxy_port = policy->proxy_port;
	if (unlikely(policy->auth_type)) {
		if (ext_err)
			*ext_err = (__s8)policy->auth_type;
		return DROP_POLICY_AUTH_REQUIRED;
	}
	return CTX_ACT_OK;
}
    \end{lstlisting}
    \caption{Block of code reached after a goto \jinghao{This code is not referenced}}
    \label{fig:inline-fig}
\end{figure}


An example of this was found in Cilium.
The code in Figure~\ref{fig:inline-fig} was written to check fields in a policy struct.
Originally, the code would check to see which of the variables, \verb{policy{ or \verb{l4policy{, was set.
It would then set \verb{policy{ to whichever was defined and jump to the block of code.
At that point however, the verifier was confused about the state of the \verb{policy{ variable.
The solution was to convert this block to an inlined function that would take an argument for \verb{policy{.

The structure of the code before was valid and correct, but it failed to pass the verifier.
In response to this, the developers had to figure out a workaround to make their valid code pass.

%The developers made this code general across two cases by reassigning the value of policy depending on what the input was before jumping to the common code.
%This pattern caused the verifier to lose information about what the variable \verb{policy{ was referring to.
%The fix was to convert this common code into an inlined function.
\jinghao{
It is hard to see why this is a problem, especially when you say ``Doing this
    helps to keep functionality separate from the programmers perspective,
    while allowing the verifier to see all the code at the same time''.
I think we need something similar to the previous cases where we explicitly
    discuss why it is bad.
}

%TODO
inline functions, explicitly teach info, etc

\subsubsection{Implement kernel-version-specific fixes}
Different kernel versions may have different versions of the eBPF verifier, each with different sets of bugs.
To maintain compatibility between these versions, developers have to change code to account for the differences.
A good example of this is found in Cilium.
The verifier failed the program with the message shown in Figure~\ref{fig:kernel-version}.
This is a known bug that has been fixed, but the fix is not present in all kernel versions.
Cilium developers had to implement a simple, but precise fix to ensure that the program would verify on all extensions.
As shown in Figure~\ref{fig:kernel-version-code} the fix needed was to move line 7 to line 1 before the block of code.

\milo{Not sure how to format these code snippets}
\begin{figure}
    \begin{lstlisting}[language=myC]
1411: (bf) r1 = r9
1412: (07) r1 += 48
1413: (67) r2 <<= 16
1414: (47) r2 |= 512
1415: (63) *(u32 *)(r1 +0) = r2
dereference of modified ctx ptr R1 off=48+0, 
    ctx+const is allowed, ctx+const+const 
    is not
    \end{lstlisting}
    \caption{Verifier output showing error}
    \label{fig:kernel-version}
\end{figure}

\begin{figure}
    \lstinputlisting[language=myC]{./snippets/s2-kernel-version.c}
    \caption{Kernel version specific fix}
    \label{fig:kernel-version-code}
\end{figure}

\subsubsection{Add Pruning Checkpoints}
Another common fix that Cilium implemented was to introduce a pseudo-helper function \texttt{relax\_verifier}.
The purpose of this helper is to provide a checkpoint for the verifier to use when does state pruning
\jinghao{Not sure if it should be ``which does'' or ``when doing''}.
In some cases doing so significantly decreases the complexity of eBPF programs.
In one commit, doing so reduced the number of instructions checked from 62,569 to 49,669.
This is more significant on older kernel versions which have a much smaller upper limit to the number of instructions the eBPF verifier could check.

Again, this change is horrible from a usability standpoint.
With no assistance from their compiler, programmers must know the design and then include code that enables the verifier's state pruning mechanism to kick in.



\subsection{Key Takeaways}
From our analysis, we believe that there are serious usability challenges to the existing eBPF system that stem from the gap between programmer and verifier.
The categories of verifier issue that we found are direct indicators of this problem.
eBPF programmers have to implement arcane fixes and change the mental model of programming to meet the constraints of the verifier.
On its own this is not bad, and an expected outcome of using a verifier
\jinghao{what does this sentence mean?}.
But with the current system, developers are actively hindered by the system.
If an eBPF program fails to verify there is not always a clear reason why that was the case, e.g.,
it could be that a programmer's source code was completely safe, but LLVM generated code that the verifier did not understand.
To programmers, a successful compilation should indicate something about the success of their code, but in the eBPF system that is not the case.

This gap is fundamental to the eBPF system.
Different kernel versions have different verifiers with different constraints and different properties that they check.
There would have to be some way to fully expose the specifics of the verifier back to the compiler to close the gap.

\jinghao{would be interesting to talk about saving/reloading computation
    context across tail calls}
