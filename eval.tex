\section{Evaluation}

\begin{itemize}
    \item Macro-benchmark
        \begin{itemize}
            \item BMC
                \begin{itemize}
                    \item Expressiveness: how to evaluate?
                        \begin{itemize}
                            \item LOC: we have 33\% reduction
                            \item 1 rust program vs 7 eBPF programs
                            \item based on experience?
                            \item Rust is a safer language
                        \end{itemize}
                    \item Performance evaluation
                        \begin{itemize}
                            \item Check their paper to see if we can perform
                                the same experiment
                            \item We want a figure similar to Figure 6 in BMC
                                (except we don't need to evaluate on different
                                CPU configs)
                            \item x: Vanilla memcached, BMC, Rust
                            \item y: normalized throughput

                        \end{itemize}
                \end{itemize}
            \item Electrode
                \begin{itemize}
                    \item LOC reduction
                    \item Performance using their benchmark (similar to figure
                        5 and 7 in Electrode)
                    \item Dynamic allocation (ask the authors)
                \end{itemize}
            \item LSM implementation (if we have time / requires handle
                nesting)
            \item XRP
            \item FUSE in eBPF (from Hubertus)
        \end{itemize}
    \item Micro-benchmark
        \begin{itemize}
            \item Memory footprint (BPF vs Rust) given we have a larger binary
                \begin{itemize}
                    \item Number of prog in the same translation unit vs memory
                        usage for program allocation
                    \item This is because we are always statically linked to
                        the runtime crate on the translation unit basis
                    \item E.g. a bpf kern.c with 4 programs vs a rust main.rs
                        with 4 programs
                \end{itemize}
            \item Small expressiveness examples
                \begin{itemize}
                    \item Loop: strcmp
                    \item need more
                \end{itemize}
            \item Stack-check overhead
                \begin{itemize}
                    \item Use BMC?
                    \item Or create some other workload that are function call
                        intensive (since our instrumentation happens before
                        each function call)
                \end{itemize}
            \item Cleanup overhead on normal execution path (recording
                allocated kernel objects)
                \begin{itemize}
                    \item Similar to Stack-check
                \end{itemize}
            \item Startup overhead due to stack switching
                \begin{itemize}
                    \item A minimal program () to show the upper bound?
                    \item Plus a real world application (again BMC)?
                \end{itemize}
        \end{itemize}
\end{itemize}

\subsection{Macro-benchmarks}
We now demonstrate that \projname{} can be used to implement complicated,
    real-world kernel extension use cases with enhanced usability but without
    losing much performance by implementing BMC and Electrode in \projname{}.

\subsubsection{\projname{}-based BMC}
% \jinghao{TODO: Preamable}
% BMC implements in-kernel memcached cache -- how it works
% Compilcated program, original paper splits into 7 programs and uses tail calls
%

BMC~\cite{BMC} is an in-kernel cache for Memcached based on eBPF.
It stores recently queried key-value pairs in an eBPF map to accelerate the
    processing of GET requests to the Memcached server.
If a GET is hit in the cache, the queried value can be sent in a reply without
    going through the expensive network stack in the Linux kernel.
The map that servers as the cache is managed by eBPF programs, which implements
    the lookup and update logics.

On the aspect of implementation, BMC is a much more complicated program
    comparing to other common eBPF use cases.
In order to pass the verifier, the implementation has to be splitted into seven
    eBPF programs that tail-calls into each other to reduce verification
    complexity.
Similar problem also presents when processing the incoming packet data, where
    the authors had to bound data size to reduce verification complexity for
    loops.

We re-implement BMC in \projname{} to demonstrate the enhanced usability
    without losing performance.

%\para{Experiment setup}
Our evaluation setup consists two machines, with one
    acting as the server and the other one acting as the client.
The server machine runs the \projname{} custom kernel on an AMD EPYC 7551P
    32-Core processor with 112 GB memory.
SMT and Turbo are turned off for the experiments.
The client machine runs a vanilla v6.7.8 Linux kernel on AMD Ryzen 9 7900X
    processor with 64 GB memory.
Both machines are equiped with Mellanox ConnectX-3 Pro 40GbE NICs and are
    connected back-to-back.

% Key: 16 bytes, value: 32 bytes
% 100 million with Zipf 0.99
% 10 GB memcached, 2.5 GB BMC
% Preload all keys
% GET:SET 30:1

We use a workload with the same specs as in BMC.
Our dictionary contains 100 million Memcached keys following a Zipf
    distribution with 0.99 skewness.
All keys are 16 bytes in size and are paired with 32-byte values in the
    experiments.
The storage sizes of the Memcached and BMC are set to 10 GB and 2.5 GB,
    respectively.
According to the calculation in the original work, around 89 million items
    can be stored in Memcached itself and 6.3 million of them can fit in
    BMC.
Before experiments, the Memcached server is pre-loaded with all keys by
    sending TCP SET requests for each key in the dictionary from the client.
The client then sends requests to the server with a 30:1 ratio betweren UDP GET and
    TCP SET requests and measures the throughput.
